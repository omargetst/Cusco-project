# Cusco-project
# ğŸ§  Asistente con Ollama â€“ Interfaz de Chat Multimodal

Este proyecto proporciona una interfaz interactiva construida con [Streamlit](https://streamlit.io) que se conecta con el modelo LLM de **Ollama**. El asistente puede recibir entradas de texto, leer documentos PDF e interpretar imÃ¡genes para ofrecer respuestas contextuales y Ãºtiles.

---

## ğŸš€ CaracterÃ­sticas principales

- âœ… **Chat en lenguaje natural** con modelo de lenguaje vÃ­a Ollama
- ğŸ“ **Carga de archivos PDF o imÃ¡genes** como contexto adicional (JPG, PNG)
- ğŸ’¬ **Historial de mensajes** y copia rÃ¡pida de respuestas
- ğŸ¨ **DiseÃ±o moderno y responsivo**
- ğŸŒ™ **Modo centrado o ancho** intercambiable
- ğŸ§  **Respuestas enriquecidas** con Markdown (listas, cÃ³digo, etc.)
- ğŸ“‹ **BotÃ³n de copiar respuesta al portapapeles**
- ğŸ–¥ï¸ Listo para ejecutar en [Streamlit Cloud](https://streamlit.io/cloud)

---

## ğŸ“· Captura de pantalla

![demo](https://github.com/tu-usuario/tu-repo/assets/demo.png)

---

## ğŸ› ï¸ Estructura del proyecto

